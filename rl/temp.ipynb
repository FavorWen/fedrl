{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger('')\n",
    "logger.setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim):\n",
    "        super().__init__()\n",
    "        self.obs_dim = obs_dim\n",
    "        self.act_dim = act_dim\n",
    "        p_hidden_size = 100\n",
    "        l_hidden_size = 100\n",
    "        hidden_size = 100\n",
    "\n",
    "        hdim = obs_dim // (act_dim+1)\n",
    "\n",
    "        self.participant_branch = nn.Sequential(\n",
    "            nn.Linear(hdim * act_dim, p_hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.loss_branch = nn.Sequential(\n",
    "            nn.Linear(hdim, l_hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.merge = nn.Sequential(\n",
    "            nn.Linear(p_hidden_size + l_hidden_size, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def transfer(self, x):\n",
    "        p = x[..., :-1]\n",
    "        l = x[..., -1:]\n",
    "        return p.reshape(p.size(0), -1), l.reshape(l.size(0), -1)\n",
    "    def forward(self, x):\n",
    "        p, l = self.transfer(x)\n",
    "        pb = self.participant_branch(p)\n",
    "        lb = self.loss_branch(l)\n",
    "        x = torch.cat([pb, lb], dim=-1)\n",
    "        return self.merge(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x += residual  # 跳跃连接\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ModelRes(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim):\n",
    "        super().__init__()\n",
    "        self.obs_dim = obs_dim\n",
    "        self.act_dim = act_dim\n",
    "        p_hidden_size = 50\n",
    "        l_hidden_size = 50\n",
    "        hidden_size = 50\n",
    "        num_blocks = 2\n",
    "        hdim = obs_dim // (act_dim+1)\n",
    "\n",
    "        self.participant_branch = nn.Sequential(\n",
    "            nn.Linear(hdim * act_dim, p_hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.loss_branch = nn.Sequential(\n",
    "            nn.Linear(hdim, l_hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.merge = nn.Sequential(\n",
    "            nn.Linear(p_hidden_size + l_hidden_size, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.res_blocks = nn.Sequential(*[ResidualBlock(hidden_size, hidden_size) for _ in range(num_blocks)])\n",
    "        self.net = nn.Sequential(\n",
    "            self.merge,\n",
    "            self.res_blocks,\n",
    "            nn.Linear(hidden_size, act_dim),\n",
    "            # nn.Softmax(dim=1),\n",
    "        )\n",
    "    def transfer(self, x):\n",
    "        p = x[..., :-1]\n",
    "        l = x[..., -1:]\n",
    "        return p.reshape(p.size(0), -1), l.reshape(l.size(0), -1)\n",
    "    def forward(self, obs):\n",
    "        p, l = self.transfer(obs)\n",
    "        pb = self.participant_branch(p)\n",
    "        lb = self.loss_branch(l)\n",
    "        obs = torch.cat([pb, lb], dim=-1)\n",
    "        return self.net(obs)\n",
    "\n",
    "class ModelResSoft(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim):\n",
    "        super().__init__()\n",
    "        self.obs_dim = obs_dim\n",
    "        self.act_dim = act_dim\n",
    "        p_hidden_size = 50\n",
    "        l_hidden_size = 50\n",
    "        hidden_size = 50\n",
    "        num_blocks = 2\n",
    "        hdim = obs_dim // (act_dim+1)\n",
    "\n",
    "        self.participant_branch = nn.Sequential(\n",
    "            nn.Linear(hdim * act_dim, p_hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.loss_branch = nn.Sequential(\n",
    "            nn.Linear(hdim, l_hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.merge = nn.Sequential(\n",
    "            nn.Linear(p_hidden_size + l_hidden_size, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.res_blocks = nn.Sequential(*[ResidualBlock(hidden_size, hidden_size) for _ in range(num_blocks)])\n",
    "        self.net = nn.Sequential(\n",
    "            self.merge,\n",
    "            self.res_blocks,\n",
    "            nn.Linear(hidden_size, act_dim),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "    def transfer(self, x):\n",
    "        p = x[..., :-1]\n",
    "        l = x[..., -1:]\n",
    "        return p.reshape(p.size(0), -1), l.reshape(l.size(0), -1)\n",
    "    def forward(self, obs):\n",
    "        p, l = self.transfer(obs)\n",
    "        pb = self.participant_branch(p)\n",
    "        lb = self.loss_branch(l)\n",
    "        obs = torch.cat([pb, lb], dim=-1)\n",
    "        return self.net(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import Camera\n",
    "import pickle\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearmanFromActProb(rank, act_prob):\n",
    "    x = [act_prob[i] for i in rank]\n",
    "    y = [c for c in range(len(rank))]\n",
    "    return scipy.stats.spearmanr(x,y)[0]\n",
    "def spearmanSequenceFromActProbList(rank, act_probList):\n",
    "    cos = []\n",
    "    for act_prob in act_probList:\n",
    "        cos.append(spearmanFromActProb(rank, act_prob))\n",
    "    return np.array(cos)\n",
    "def evaluateContributionsFromLogs(logs, client_nums):\n",
    "    contirbution = []\n",
    "    ddl = len(logs)\n",
    "    for r in range(ddl):\n",
    "        contirbution.append([0 for c in range(client_nums)])\n",
    "    pprev_acc = logs[0].acc\n",
    "    prev_participants = logs[1].participants\n",
    "    prev_acc = logs[1].acc\n",
    "    for r in range(2, ddl):\n",
    "        for c in range(client_nums):\n",
    "            contirbution[r][c] = contirbution[r-1][c]\n",
    "        participants, acc = logs[r].participants, logs[r].acc\n",
    "        if acc - prev_acc > prev_acc - pprev_acc:\n",
    "            for c in prev_participants:\n",
    "                contirbution[r][c] -= 1\n",
    "            for c in participants:\n",
    "                contirbution[r][c] += 1\n",
    "        \n",
    "        if acc < prev_acc:\n",
    "            for c in participants:\n",
    "                contirbution[r][c] -= 1\n",
    "    return contirbution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5574917491749174, 0.034013848222753246)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('camera/cn5_pn3_dFMNIST_aMLP_piid_seed2.camera', 'rb') as f:\n",
    "    camera = pickle.load(f)\n",
    "curr_round = 4\n",
    "act_probs = camera.act_probLogs[curr_round]\n",
    "contributions = evaluateContributionsFromLogs(camera.getRpmLogs(curr_round), camera.client_nums)\n",
    "sco_rl = spearmanSequenceFromActProbList(camera.rank, act_probs)\n",
    "sco_qi = spearmanSequenceFromActProbList(camera.rank, contributions)\n",
    "sco_rl[199], sco_qi[199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4913171317131712, 0.4146991669867845)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sco_rl[199], sco_qi[199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4072857142857143,\n",
       " 0.058279946225030084,\n",
       " array([37, 33, 36, 39,  0, 56, 12, 24,  3, 99]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = rpm.buffer[r]\n",
    "log.acc, log.loss, log.participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logs = [rpm.buffer[i] for i in range(8, 209)]\n",
    "contributions = evaluateContributionsFromLogs(logs, camera.client_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4146991669867845, 0.48400840084008395)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "s1 = spearmanFromActProb(camera.rank, contributions[199])\n",
    "s2 = spearmanFromActProb(camera.rank, camera.act_probLogs[curr_round][199])\n",
    "s1, s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "bs = 2\n",
    "act_dim = 3\n",
    "h_dim = 2\n",
    "obs_dim = (act_dim + 1) * h_dim\n",
    "print(obs_dim)\n",
    "m1 = ModelRes(obs_dim=obs_dim, act_dim=act_dim)\n",
    "m2 = ModelResSoft(obs_dim=obs_dim, act_dim=act_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2650, 0.4232, 0.3119],\n",
       "         [0.2331, 0.4504, 0.3166]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.2650, 0.4232, 0.3119],\n",
       "         [0.2331, 0.4504, 0.3166]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn([bs,1 , h_dim, act_dim+1])\n",
    "p = m1(x)\n",
    "soft1 = nn.Softmax(dim=1)\n",
    "soft2 = F.softmax\n",
    "p1 = soft1(p)\n",
    "p2 = soft2(p, dim=-1)\n",
    "p1, p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2851, 0.4292, 0.2857],\n",
       "        [0.3004, 0.3787, 0.3209]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(p1,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [i for i in range(0, 32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[-64:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = nn.BCEWithLogitsLoss(reduction='none')\n",
    "g = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.7762, 0.7756, 0.8213],\n",
       "         [0.6489, 0.6156, 0.8133]],\n",
       "        grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
       " tensor(0.7418, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(pred, one_hots), g(pred, one_hots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7762, 0.7756, 0.8213],\n",
       "        [0.6489, 0.6156, 0.8133]],\n",
       "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = f(pred, one_hots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9001],\n",
       "        [-0.2279]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6986, -0.6981, -0.7392],\n",
       "        [-0.1479, -0.1403, -0.1853]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t * rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m tensor \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 将张量形状变为[a, c * d]\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m reshaped_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m reshaped_tensor\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "tensor = torch.randn(2, 1, 2, 4)  # 假设形状为[2, 1, 3, 4]\n",
    "\n",
    "# 将张量形状变为[a, c * d]\n",
    "reshaped_tensor = tensor.view(tensor.size(0), -1)\n",
    "reshaped_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 101])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn([4, 26])\n",
    "x.unsqueeze(0).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "192/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0063, 0.0088, 0.0052, 0.0104, 0.0117, 0.0149, 0.0042, 0.0177, 0.0145,\n",
       "         0.0126, 0.0185, 0.0101, 0.0089, 0.0083, 0.0085, 0.0071, 0.0065, 0.0096,\n",
       "         0.0076, 0.0090, 0.0086, 0.0087, 0.0123, 0.0064, 0.0098, 0.0198, 0.0127,\n",
       "         0.0047, 0.0045, 0.0122, 0.0080, 0.0050, 0.0077, 0.0074, 0.0092, 0.0072,\n",
       "         0.0068, 0.0070, 0.0136, 0.0060, 0.0074, 0.0058, 0.0151, 0.0072, 0.0059,\n",
       "         0.0175, 0.0125, 0.0095, 0.0078, 0.0152, 0.0197, 0.0080, 0.0052, 0.0149,\n",
       "         0.0094, 0.0080, 0.0137, 0.0151, 0.0110, 0.0049, 0.0029, 0.0084, 0.0132,\n",
       "         0.0051, 0.0131, 0.0140, 0.0225, 0.0103, 0.0127, 0.0049, 0.0108, 0.0102,\n",
       "         0.0099, 0.0047, 0.0082, 0.0087, 0.0043, 0.0092, 0.0064, 0.0075, 0.0113,\n",
       "         0.0117, 0.0096, 0.0129, 0.0056, 0.0069, 0.0111, 0.0087, 0.0215, 0.0091,\n",
       "         0.0065, 0.0239, 0.0126, 0.0122, 0.0142, 0.0099, 0.0122, 0.0078, 0.0092,\n",
       "         0.0043],\n",
       "        [0.0059, 0.0099, 0.0168, 0.0112, 0.0080, 0.0091, 0.0171, 0.0086, 0.0055,\n",
       "         0.0081, 0.0095, 0.0069, 0.0105, 0.0106, 0.0159, 0.0065, 0.0074, 0.0145,\n",
       "         0.0144, 0.0062, 0.0111, 0.0087, 0.0105, 0.0062, 0.0080, 0.0064, 0.0080,\n",
       "         0.0081, 0.0088, 0.0116, 0.0154, 0.0078, 0.0107, 0.0050, 0.0209, 0.0062,\n",
       "         0.0114, 0.0051, 0.0105, 0.0108, 0.0091, 0.0044, 0.0157, 0.0071, 0.0140,\n",
       "         0.0051, 0.0100, 0.0085, 0.0106, 0.0053, 0.0088, 0.0139, 0.0104, 0.0084,\n",
       "         0.0134, 0.0071, 0.0101, 0.0087, 0.0040, 0.0112, 0.0086, 0.0077, 0.0070,\n",
       "         0.0045, 0.0123, 0.0136, 0.0089, 0.0167, 0.0156, 0.0102, 0.0049, 0.0161,\n",
       "         0.0091, 0.0065, 0.0064, 0.0176, 0.0048, 0.0092, 0.0077, 0.0227, 0.0199,\n",
       "         0.0102, 0.0085, 0.0107, 0.0075, 0.0073, 0.0080, 0.0073, 0.0061, 0.0115,\n",
       "         0.0078, 0.0209, 0.0056, 0.0072, 0.0066, 0.0169, 0.0100, 0.0182, 0.0139,\n",
       "         0.0063]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn([2,1,4,26])\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 4 * 101\n",
    "kernel_size = 3\n",
    "padding = 1\n",
    "stride = 1\n",
    "(input_size - kernel_size + 2 * padding) / stride + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
